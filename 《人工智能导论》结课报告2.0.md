## 背景：
这学期笔者选了学校的《计算机科学与技术导论》。到了写大作业的时候，一开始想着抄上学期的人工智能导论的论文所以小组展示和个人论文都选的人工智能，直到我论文写完了才知道小组展示和个人论文的主题不能选同一个。我就又重新写了份数据结构和算法的论文，结果小组展示完了之后老师觉得我讲得不错又鼓励我写人工智能的论文。这个故事告诉我们**学人工智能的结局是损失最大化**。  
 **P.S.** 这篇论文在我的上一篇《<人工智能导论>结课报告》的基础上整理了人工智能的定义、发展历史、原理、应用、最新研究热点与挑战性问题等内容，如有需要也可以借（Ctrl+C）鉴（Ctrl+V）一下。  
# 一、人工智能的定义
在公众的心目中，人工智能就是能完成人们不认为机器能胜任的事的机器——这反映了绝大多数普通人在特定的时代对人工智能的朴素认识。  
在人工智能发展的早期阶段，人们把它定义为与人类思考方式相近的计算机程序，并从这个定义出发，人们让人工智能程序根据人类已有的只是与智慧，遵循逻辑学基本原理进行推理、运算、归纳，实现了专家系统。  
科学上流行的定义是，人工智能就是和人类行为相似的计算机程序。这个定义突破了早期定义对人工智能思考方式的束缚，人们开发出了CNN、RNN等神经网络，让机器以自己的方式来思考和学习而无需和人类一样，最后通过输出的结果来判断机器是否具有智能。  
而实用主义则认为，无论计算机的思考或学习以何种程序实现，只要在特定领域、特定时空下表现得和人类相近，就说该程序在该领域内具有人工智能。  
图灵曾提出过著名的图灵测试：如果一台机器能够与人类展开对话而不能被辨别出其机器身份，那么称这台机器具有智能。他还认为，实现一个达到八岁小孩智能的人工智能，再让它通过学习达到成年人的智能，比直接实现一个达到成年人智能的人工智能现实得多。从这一信条出发，我们可以定义人工智能为会学习的计算机程序。在由深度学习的突破引发的最近这一波热潮之中，人工智能在人们眼里就是一个会学习的机器，这不仅符合人类认知规律，也是今天AI模型开发的主导思想。  
综合上述各种定义，我们可以认为，人工智能就是根据环境的感知做出合理的行动，并希望从中获得最大收益的计算机程序。从这一定义出发，人们设计出了强化学习算法。  
# 二、发展历史
计算机发展刚开始不久，人们便掀起了一阵探讨机器智能的热潮，史称人工智能的第一次热潮。1950年，人工智能之父图灵发表一篇论文《计算机械和智能》。1956年夏天的达特茅斯会议上，John McCarthy首次提出了Artificial Intelligence的概念。第一次热潮中对人工智能所做的研究都可以归结为符号主义。  
1970年开始，人工智能的研究进入了第一次寒冬。当时，即使是最杰出的人工智能程序也只能解决最简单的一部分问题。同时，计算机的内存和处理速度还非常有限，使它无法解决指数级复杂度的问题。人们对于人工智能的期望也过高，期望着人工智能很快能达到人类的水平，事实上当时的这些人工智能甚至缺乏最起码的一些常识，这些并不是通过符号主义的逻辑推理能够获取的，因为这些常识涉及到了对物理世界一些感知上的认识。  
1980年，人工智能的研究迎来了第二次热潮，专家系统的研究取得了突破，联结主义获得了发展，但不久又进入了第二次寒冬。随着台式机的兴起，专家系统的市场需求被台式机取代，政府对专家系统的研究也停止了拨款。同时，人类专家和程序设计工程师的缺乏，计算机的普及有限，使得专家系统的应用也十分局限。  
第三次热潮大约从上世纪末至今，传统的基于符号主义的技术被舍弃，基于统计模型的技术兴起。由于互联网的繁荣，使得可用的数据量剧增，驱动着人工智能的技术方法实现了量变到质变的飞跃。随着神经网络技术的突破，人们用多重神经网络来搭建出更多更复杂的神经网络，有效提高了网络解决问题的能力。计算机硬件的飞速发展，实现了多达数万台高性能计算机的并行计算，满足了处理大数据和复杂模型所需的算力。与前两次热潮不同，这次热潮中的很多产品都能在生活中使用，社会对其的需求也日益增加。  
# 三、人工智能五大流派
1、符号主义：理论基础是逻辑学原理。主张通过数理逻辑，使用数学和物理学中的逻辑符号搭建出的一个个”if-then”语句进行逻辑推理来解决问题。典型算法是规则算法、决策树算法和随机森林算法。其早期应用为专家系统，在计算机代数、自然语言处理、语音识别领域亦得到了广泛应用。  
2、联结主义：理论基础是神经网络及神经网络间的连接机制与学习算法，通过用连接着的大量神经元对大量数据进行特征提取来感知世界。这一思想的来源是生物神经系统的结构。典型算法是神经网络。其在图像识别、语音识别、自然语言处理、游戏等领域均取得了远超其他流派的优异成绩。  
3、行为主义：理论基础是控制论及感知-动作型控制系统，通过行为和反馈，训练和奖惩实现最优化。典型算法是遗传算法和强化学习。其广泛应用于自动控制、机器人、自动驾驶、游戏等领域。  
4、贝叶斯派：理论基础是基于贝叶斯主义的概率统计理论，主张通过用似然函数修正先验信息得到后验分布来描述客观世界。典型算法是贝叶斯网络、马尔科夫链、LDA模型。其主要应用于时序数据建模，在语音识别、自然语言处理、新闻分类、推荐系统等领域亦得到了广泛应用。  
5、Analogizer: 理论基础是约束优化理论，主张通过定义一个损失函数，通过迭代的方式不断优化以找到最优解，并确保最优解满足约束条件。典型算法是支持向量机，其主要应用于数据分析领域。  
# 四、人工智能的应用
## 1、无人驾驶汽车
无人驾驶汽车是智能汽车的一种，也称为轮式移动机器人，主要依靠车内以计算机系统为主的智能驾驶控制器来实现无人驾驶。其核心技术有识别技术、决策技术、定位技术、通信安全技术、人机交互技术、物联网技术等，并依赖于视频摄像头、雷达传感器、激光测距器等硬件设施的性能。  
## 2、人脸识别
人脸识别是一种基于人的脸部特征信息提取进行身份识别的生物识别技术。其核心技术有计算机视觉、模型理论、专家系统、视频图像处理等。  
## 3、机器翻译
机器翻译是计算语言学的一个分支，是利用计算机将一种自然语言转换为另一种自然语言的过程。机器翻译用到的技术主要是自然语言处理领域的基于神经网络或统计模型的翻译技术。  
## 4、声纹识别
声纹识别是一种通过分析和比较语音波形中反映说话人生理和行为特征的语音参数，来识别说话人身份的生物特征识别技术。其核心技术有语音信号处理、声纹特征提取、声纹建模、声纹比对和判别决策等。  
## 5、智能客服机器人
智能客服机器人是一种利用机器模拟人类行为的人工智能实体形态，它能够实现语音识别和自然语义理解，具有业务推理、话术应答等能力。其核心技术有自然语言处理技术、知识地图技术、人工智能语音智能出站呼叫技术和用户需求智能提取。  
## 6、智能外呼机器人
智能外呼机器人是人工智能在语音识别方面的典型应用，它能够自动发起电话外呼，以语音合成的自然人声形式，主动向用户群体介绍产品。其核心技术设计多方面的技术，如电话平台、语音识别、语义识别、对话系统、语音合成等。  
## 7、智能音箱
智能音箱是语音识别、自然语言处理等人工智能技术的电子产品类应用与载体，随着智能音箱的迅猛发展，其也被视为智能家居的未来入口。智能音箱可以在指引下，提供如点歌、定闹钟、听书等功能，做到事事有回应。在同一生态下，甚至可以控制家中其他智能电器，如开关、电视机、智能厨电、扫地机器人等。其核心技术有麦克风阵列、语音识别、内容推荐算法等。  
## 8、个性化推荐
个性化推荐是一种基于聚类与协同过滤技术的人工智能应用，它建立在海量数据挖掘的基础上，通过分析用户的历史行为建立推荐模型，主动给用户提供匹配他们的需求与兴趣的信息，如商品推荐、新闻推荐等。个性化推荐既可以为用户快速定位需求产品，弱化用户被动消费意识，提升用户兴致和留存黏性，又可以帮助商家快速引流，找准用户群体与定位，做好产品营销。其核心技术有数据挖掘、机器学习、自然语言处理等。  
## 9、医学图像处理
医学图像处理是目前人工智能在医疗领域的典型应用，它的处理对象是由各种不同成像机理，如在临床医学中广泛使用的核磁共振成像、超声成像等生成的医学影像。其核心技术有图像增强、去噪、分割、特征提取、三维重建。  
## 10、图像搜索
图像搜索是近几年用户需求日益旺盛的信息检索类应用，分为基于文本的和基于内容的两类搜索方式。其核心技术有特征提取、相似度匹配、搜索引擎技术等。  
# 五、最新研究热点
## 1、Sora实现文生视频领域新突破
2024年2月16日OpenAI发布文生视频大模型Sora，其可通过100字上下的文字描述生成一段60秒的视频。  
Sora的设计思路和LLM一致，都是先将训练数据统一化（LLM的训练数据是文本，Sora的训练数据是视频），再用于输出预测值（LLM输出文本，Sora输出视频）。其间，LLM学习单词排列的规则，而Sora学习物理世界。  
具体实现：Sora对原始数据降维、下采样、特征提取后，使用引入了Attention机制的Transformer模型输出预测，即编码器对所有时间步的隐藏状态做加权平均来得到背景变量，而解码器在每⼀时间步调整这些权重，即注意⼒权重，从而能够在不同时间步分别关注输⼊序列中的不同部分并编码进相应时间步的背景变量。  
目前，Sora仍存在着无法准确模拟不同物体接触挤压处、无法准确模拟复杂场景的物理特性，可能无法理解物理场景的因果关系，可能混淆提示中的空间细节等缺陷。  
## 2、百度弱智吧成为最佳中文AI训练数据
现今，中文大模型训练中存在诸多问题，如：1）中文数据集大多来自于英文翻译， 不能很好契合中文语言习惯和文化背景；2）不少数据集是用AI生成的，质量参差不齐且存在事实性错误；3）人工标注的数据集数据量小，覆盖领域不全面。  
在2024年3月26日由中科院发表的论文Quality is All You Need for Chinese Instruction Fine-tuning中，为解决这些痛点难点，团队从中文互联网的各种知识源头直接收集数据，如知乎、豆瓣、维基、小红书等，经过一系列严格的清洗和人工审核，力求打造高质量且具文本多样性的中文指令微调数据集。  
在众多不同的数据来源中，弱智吧是百度贴吧的一个子论坛，其帖子经常包含双关语、多义词、同音词和逻辑陷阱，对人类而言，识别出它们甚至也是挑战。研究人员从中收集了500个点赞最多的帖子制作数据集，使用该数据集训练的模型在开放式问答、头脑风暴、分类、生成、总结、封闭式问答、 提取、代码8个项目下都拿到了最高分。导致该结果的可能原因是弱智吧的语料用词准确，且能有效增强AI的逻辑能力。  
# 六、挑战性问题：让AI真正融入到人类的生活方式
如今的AI发展可能因为ChatGPT的成功陷入了大模型陷阱,也就是GPT类的语言模型已经冗余，同等参数量级下的重复造轮子无法再产生质变。而其实AI有非常多的领域，并不只是大模型。除了OpenAI等头部机构，大模型赛道其实并不需要这么多人参与。对用户而言，我们需要的不是一个个泡在海量算力训练出的差别不大的聊天机器人，而是差异化的，能够对生活产生真正影响的人工智能。其实上个月OpenAI发布的GPT-4一系列新版本算是给这一年的NLP大模型画了一个年终总结。作为大模型革命的先驱，不可否认，这将是生产力的又一变革。但正如其创始人阿尔特曼所说，如今的GPT范式只是走向通用人工智能的垫脚石。毕竟AI可以是提高工作效率的工具，但不能只是工具——这就是我今天要表达的观点。虽然AI的确带来了生产力的变革，它可以写出华丽的文章、完美的图表，生成以假乱真的图片和声音，如果只是图一乐，作为玩具，未尝不可。但正如AI之父艾伦图灵在论文《计算机器与智能》中说，“人工智能的初衷，就是开发出一种能够像人类一样思考的机器，让它们完成人类所能以及人类所不能完成的工作。”结果到了2023年，AI成了聊天、写文档、画图、制表的代名词——这绝不是我们曾经想象的人工智能。我们要的不只是写PPT、写文章的同质化工具，而是能打破维度限制、触及现实生活的人工智能。要么像科幻作品中所描述的那样，以人形机器人为载体，AI就能真正融入人类的生活方式，但问题在于成本。不论特斯拉还是宇树科技，一台机器人的价格都在10到50万元之间——这并不是普通人能承受的。要么让AI融入周围的环境，仅靠一个大模型操作系统来完成与所有物联设备的交互。在我看来这才是摆脱大模型陷阱的最优解。现在让我们试想一下，假如这条路真的可行，又该如何去实现呢？很可惜，目前还没有任何一家大模型可以做到像电影中那样的无界互联。这依赖大量智能设备，并且这些设备必须处于同一生态。
